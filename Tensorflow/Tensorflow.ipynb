{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>There are different tensorflow API's. The lowest level API is Tensorflow Core. Some higher level API's are tf.estmator</p>\n",
    "\n",
    "### Tensors\n",
    "<p>The rank of a tensor is its number of dimensions.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Tensorflow core programs can be thought of as first building the computation graph and then runing the computation graph</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_1:0\", shape=(), dtype=float32) Tensor(\"Const_2:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3. , dtype = tf.float32)\n",
    "node2 = tf.constant(4.)\n",
    "print(node1 , node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "# To run the computation graph we use Session\n",
    "sess = tf.Session()\n",
    "print(sess.run([node1 , node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node3: Tensor(\"Add_1:0\", shape=(), dtype=float32)\n",
      "sess.run(node3): 7.0\n"
     ]
    }
   ],
   "source": [
    "node3 = tf.add(node1 , node2)\n",
    "print(\"node3:\" , node3)\n",
    "print(\"sess.run(node3):\" , sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>To view the computation graph we use tensorboard</p>\n",
    "<p>Now to create variables without assigning them values we use placehodlers</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(dtype = tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.0\n",
      "[  5.  10.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node , {a:3. , b:4.}))\n",
    "print(sess.run(adder_node , {a:[1. , 3.] , b:[4. , 7.]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To add trainable parameters in tensorflow we have to use Variables\n",
    "W = tf.Variable([.3] , dtype=tf.float32)\n",
    "b = tf.Variable([-.3] , dtype=tf.float32)\n",
    "x = tf.placeholder(tf.float32)\n",
    "linear_model = W*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Constants are initialized using tf.constant and you cannot reinitialize them\n",
    "# To initialize variables we use tf.global_varibales_initializer() \n",
    "# as they are not initialized when you call tf.Variable\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.          0.30000001  0.60000002  0.90000004]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(linear_model , {x:[1,2,3,4]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.66\n"
     ]
    }
   ],
   "source": [
    "# Now to update our model we have to make a loss function\n",
    "y = tf.placeholder(tf.float32)\n",
    "squared_deltas = tf.square(linear_model - y)\n",
    "loss = tf.reduce_sum(squared_deltas)\n",
    "print(sess.run(loss , {x:[1,2,3,4] , y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "# When you want to assign a value to a variable\n",
    "fixW = tf.assign(W , [-1.])\n",
    "fixb = tf.assign(b , [1.])\n",
    "sess.run([fixW , fixb])\n",
    "print(sess.run(loss , {x:[1,2,3,4] , y:[0,-1,-2,-3]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.train API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([-0.9999969], dtype=float32), array([ 0.99999082], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "sess.run(init)\n",
    "for _ in range(1000):\n",
    "    sess.run(train , {x:[1,2,3,4] , y:[0,-1,-2,-3]})\n",
    "    \n",
    "print(sess.run([W,b]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tf.estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simplifies the mechanics of machine learning i.e running training,evaluation loops and managing data sets\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[1])]\n",
    "\n",
    "#tf.estimate contains many simple machine learning models like linear regression, linear classification\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns = feature_columns)\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7, 0.])\n",
    "\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({\"x\":x_train}, y_train, batch_size=4, num_epochs=None , shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\":x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=True)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\":x_eval}, y_eval, batch_size=4, num_epochs=None, shuffle=True)\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "\n",
    "print(\"train metrics: %r\"%train_metrics)\n",
    "print(\"eval metrics: %r\"%eval_,metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To create custom models use tf.estiamtor.Estimator\n",
    "def model_fn(features, labels, mode):\n",
    "    W = tf.Variable(\"W\" , [1] , dtype=tf.float32)\n",
    "    b = tf.Variable(\"b\" , [1] , dtype=tf.float32)\n",
    "    t = w*featues['x'] + b\n",
    "    \n",
    "    loss = tf.reduce_sum(tf.square(y-labels))\n",
    "    \n",
    "    #training global sub-graph\n",
    "    global_step = tf.train.get_global_step()\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = tf.group(optimizer.minimize(loss) , tf.assign_add(global_step , 1))\n",
    "    \n",
    "    #EstimateSpec connects subgraphs we built to the appropriate funcitonality\n",
    "    return tf.estimator.EstimateSpec(\n",
    "    mode=mode,\n",
    "    prediction=y,\n",
    "    loss=loss,\n",
    "    train_op=train)\n",
    "\n",
    "estimator = tf.estimator.Estimator(model_fn=model_fn)\n",
    "\n",
    "x_train = np.array([1., 2., 3., 4.])\n",
    "y_train = np.array([0., -1., -2., -3.])\n",
    "x_eval = np.array([2., 5., 8., 1.])\n",
    "y_eval = np.array([-1.01, -4.1, -7., 0.])\n",
    "input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=None, shuffle=True)\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": x_train}, y_train, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn({\"x\": x_eval}, y_eval, batch_size=4, num_epochs=1000, shuffle=False)\n",
    "\n",
    "estimator.train(input_fn=input_fn, steps=1000)\n",
    "train_metrics = estimator.evaluate(input_fn=train_input_fn)\n",
    "eval_metrics = estimator.evaluate(input_fn=eval_input_fn)\n",
    "print(\"train metrics: %r\"% train_metrics)\n",
    "print(\"eval metrics: %r\"% eval_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST For ML Beginners\n",
    "<p>It is the standard dataset that is used to quickly train your models (computer vision dataset)</p>\n",
    "<p>MNIST is analogous to \n",
    "<python>print(\"Hello, World\")</python>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# To implement Softmax Regression for hand written digit recognition\n",
    "\n",
    "# Get the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\" , one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>About the dataset\n",
    "<li>Contains 55000 training , 5000 validation and 10000 test examples</li>\n",
    "<li>mnist.train.images and mnist.train.labels to get your images and labels</li>\n",
    "<li>Images of size 28x28</li>\n",
    "<li>'One-hot vector means a vector 0 in most dimensions and 1 in a single dimension like [0,0,0,0,1,0,0]</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key to the speed of tensorflow is use of efficient numerical computing with libraries like NumPy. Now to do these computations different from Python it will have to switch back and forth between the two and it will lead to a lot of overhead. To avoid this, instead of using a single expensive operation independently from Python, Tensorflow uses a graph of operations that run entirely outside Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32 , shape=[None , 784])\n",
    "W = tf.Variable(tf.zeros([784 , 10]))\n",
    "b = tf.Variable(tf.zeros([10]))# Implementation of cross_entropy\n",
    "y_hat = tf.placeholder(tf.float32 , [None , 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_hat * tf.log(y), reduction_indices=[1]))\n",
    "# reduction_indices can be thought of ax axis of a tensor\n",
    "y = tf.nn.softmax(tf.matmul(x , W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Implementation of cross_entropy\n",
    "y_hat = tf.placeholder(tf.float32 , [None , 10])\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_hat * tf.log(y), reduction_indices=[1]))\n",
    "# reduction_indices can be thought of ax axis of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "# 0.5 is the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for _ in range (10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train, feed_dict={x: batch_xs, y_hat: batch_ys})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9263\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1) , tf.argmax(y_hat,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "print(sess.run(accuracy , feed_dict={x:mnist.test.images , y_hat:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep MNIST for Experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data' , one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32 , shape=[None,784])\n",
    "y_hat = tf.placeholder(tf.float32 , shape=[None , 10])\n",
    "W = tf.Variable(tf.zeros([784 , 10]))\n",
    "b = tf.Variable(tf.zeros([10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = tf.matmul(x,W)+b\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_hat , logits = y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n",
    "for _ in range(10000):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    sess.run(train , feed_dict={x:batch[0] , y_hat:batch[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.926\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(y,1) , tf.argmax(y_hat , 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction , tf.float32))\n",
    "print(accuracy.eval(feed_dict={x:mnist.test.images, y_hat:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now the convolutional neural network approach\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.truncated_normal(shape , stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x , W):\n",
    "    return tf.nn.conv2d(x , W , strides = [1,1,1,1] , padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x , strides = [1,2,2,1] , ksize = [1,2,2,1] , padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_conv = tf.placeholder(tf.float32 , shape=[None , 784])\n",
    "y_hat_conv = tf.placeholder(tf.float32 , shape=[None , 10])\n",
    "\n",
    "W_conv1 = weight_variable([5,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "x_image = tf.reshape(x_conv , [-1,28,28,1])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image , W_conv1) + b_conv1)\n",
    "h_pool2 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1 , keep_prob)\n",
    "\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cross_entropy_conv = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_hat_conv, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy_conv)\n",
    "correct_prediction_conv = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_hat_conv, 1))\n",
    "accuracy_conv = tf.reduce_mean(tf.cast(correct_prediction_conv, tf.float32))\n",
    "\n",
    "\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "\n",
    "for a in range(20000):\n",
    "    batch = mnist.train.next_batch(50)\n",
    "    if (a % 100 == 0):\n",
    "        train_accuracy = accuracy.eval(feed_dict={x_conv: batch[0], y_hat_conv: batch[1], keep_prob: 1.0})\n",
    "        print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x_conv: batch[0], y_hat_conv: batch[1], keep_prob: 0.5})\n",
    "\n",
    "print('test accuracy %g' % accuracy.eval(feed_dict={x_conv: mnist.test.images, y_hat_conv: mnist.test.labels, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre made Estimators\n",
    "<p>Don't have to worry about graph or sessions since Estimators handle all the \"plumbing\" for you</p>\n",
    "<p>Structure of a pre-made estimator<br>\n",
    "<ol>\n",
    "<li>Write one or more dataset importing functions where it should return two things, a dictionary with keys are feature names and values are the Tensrs and a Tensor containing one or more labels</li>\n",
    "<li>Define the feature columns. tf.feature_column identifies a feature name and its type and any input preprocessing.</li>\n",
    "<li>Instantiate the relevant pre-made Estimator.Instantialization means creating a object</li>\n",
    "<li>Call a training, evaluation or inference method</li>\n",
    "</ol></p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1 step\n",
    "def input_fn(dataset):\n",
    "    # manipulate it to extract feature names and the labels\n",
    "    return feature_dict , label\n",
    "\n",
    "# 2 step\n",
    "a = tf.feature_column.numeric_column('a')\n",
    "b = tf.feature_column.numeric_column('b')\n",
    "\n",
    "# 3 step\n",
    "estimator = tf.estimator.Estimate.LinearClassifier(feature_columns=[a,,b])\n",
    "\n",
    "# 4 step\n",
    "estimator.train(input_fn = my_training_set , steps =200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Estimators\n",
    "<p>Estimators use model-function to work, when working with Pre-made Estimators someone has already implemented them and in Custom Estimators you have to implement them</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensorflow is a framework to define and run computations involving tensors. A tensor is a generalization of vectors and matrices to potentially higher dimensions. tf.Tensor defines a computation that will eventuallly produce a value. Tensorflow programs work by first creating a computation graph for tf.Tensor and then by running parts of this graph to achieve the desired result.</p>\n",
    "<p>tf.Tensor has a data_type and a shape</p>\n",
    "<p>tf.Variable , tf.Placeholder , tf.Constant , tf.SparseTensor</p>\n",
    "<h3>Rank</h3>\n",
    "<ul>\n",
    "<li>0 - scalar</li>\n",
    "<li>1 - vector</li>\n",
    "<li>2 - matrix </li>\n",
    "<li>3 - 3-Tensor</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Rank_1:0\", shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To evaluate a tensor use Tensor.eval. It works only when a default tf.Session is active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_8:0\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# To print a tensor during debugging\n",
    "t = tf.constant([1,2,3] , dtype=tf.float32)\n",
    "print (t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now to correctly print the result\n",
    "t = tf.constant([1,2,3] , dtype=tf.float32)\n",
    "t = tf.Print(t , [t])\n",
    "result = t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add:0\", shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To create a variable use tf.get_variable\n",
    "variable = tf.get_variable('variable' , [1,2,3])\n",
    "# It will create a variable whose shape is [1,2,3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As tensorflow programs may create variables on their own for graph compuation, it is sometimes usefule to to access them from a single place i.e. why we use collections, which are namedlist of tensors, such as tf.Variable instances</p>\n",
    "<p>By default ever Variable is placed in two collections tf.GraphKeys.GLOBAL_VARIBALES(that can be shared among multiple devices) and tf.GraphKeys.TRAINABLE_VARIABLES(variables for which tensorflow will calculate gradients). If you don't want your variables to be trainable than add them to tf.GraphKeys.LOCAL_VARIABLES or give a argument trainable=False</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_local = tf.get_variable('my_local' , shape=() , collections=[tf.GraphKeys.LOCAL_VARIABLES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_non_trainable = tf.get_variable('my_non_trainable' , shape=() , trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can also explicitly add varibales to a collection\n",
    "tf.add_to_collection('collection_name' , my_variable)\n",
    "\n",
    "#To retrieve a list of all the variables in a collection\n",
    "tf.get_collection('my_collection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To select the device you want your varibale to run\n",
    "with tf.device('/device:GPU:1'):\n",
    "    v = tf.get_variable('v' , [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Variables\n",
    "to initialize all trainable variables in one go use tf.global_variables_initializer()<br>\n",
    "If you want to initialize them use sess.run(my_variable.initializer)<br>\n",
    "To print the variables not initialized print(sess.run(tf.report_uninitialized_variables()))<br>\n",
    "By default tf.global_variables_initalizer does not specify the order in which variables are intitialized, so if the value of a variable depends on another variable than you can use initializer = variable_name.initialized_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  To assign a value to a variable use tf.assign , tf.assign_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now to reuse variables you have to just change the scope\n",
    "\n",
    "test_variable = tf.get_variable('test_variable' , shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now calling it again will result in an erro\n",
    "test_variable = tf.get_variable('test_variable' , shape=())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can just lower level API for variable (explicitly)\n",
    "test = tf.Variable('test' , [1,2,3])\n",
    "test = tf.Variable('test' , [1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You can wrap them in tf.variable_scope objects (implicitly)\n",
    "with tf.variable_scope('model' , reuse=True):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs and Sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>You first make the dataflow graph and then make session to run parts of it. In higher levels API's it is already carried bythe API.</p>\n",
    "<p>The edges of the graph represent the data and the nodes represent the operation to be done on the data. Graph is the prefereed way in tensorflow because it enables parallel computing, distributed execution, compilation and portability</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.Graph\n",
    "Conatins\n",
    "<ul>\n",
    "<li>Graph structure</li>\n",
    "<li>Graph Collections</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Operation is used to create a node<br>\n",
    "tf.Tensor is used to create a edge<br>\n",
    "E.g when you call tf.constant(4.0) It creates a tf.Operation and a edge whose value is 4 and adds it to the 'default graph'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you do any tf.Operation you should give it a argument 'name' as it will enable you to look in the default graph easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"c_4:0\", shape=(), dtype=int32)\n",
      "Tensor(\"c_5:0\", shape=(), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "c_0 = tf.constant(0 , name='c')\n",
    "print (c_0)\n",
    "\n",
    "c_1 = tf.constant(2 , name='c' , dtype=tf.float64)\n",
    "print(c_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_number (x) :\n",
    "    count4 = 0\n",
    "    count7 = 0\n",
    "    numCount = 0\n",
    "    while (x != 0):\n",
    "        temp = x%10\n",
    "        if (temp == 4):\n",
    "            count4 = count4 + 1\n",
    "        if (temp == 7):\n",
    "            count7 = count7 + 1\n",
    "        numCount = numCount + 1\n",
    "    if (count4 == count7 and count4 + count7 == numCount):\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "n = int(input())\n",
    "laptop = {}\n",
    "for _ in range(n):\n",
    "    a = input().split(' ')\n",
    "    Name = a[0]\n",
    "    Price = int(a[1])\n",
    "    laptop[Name] = Price\n",
    "\n",
    "check = []\n",
    "for key in laptop:\n",
    "    check.append\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
